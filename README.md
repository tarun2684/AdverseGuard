# Adversarial ML Red Team Toolkit

ðŸ§  A tool to test ML models against adversarial attacks such as FGSM, PGD, and TextFooler.

## How to Use

```bash
python src/cli.py --model model.pkl --data test.csv --attack fgsm --attack pgd
